---
title: "poc"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{poc}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = FALSE
)
```

## Load Data

**Disclaimer**: Proof-of-concept with `eval=FALSE`, don't expect anything here to work.
Implementation might live in other branches.

Example: terra package

`demo_stack` generates a raster stack with 5 layers (4 predictor variables and 1 response variable) with a total size of 500MB. 
The file is written to disk and the stack is removed to free up memory.

```{r}
pkgload::load_all()

# see https://github.com/rspatial/terra/issues/30 for "Error in (function (x)  : attempt to apply non-function"
stack = demo_stack(size = 500, layers = 5)
# FIXME: is only 241 MB for me? and like 1,3 GB in mem
terra::writeRaster(stack, "demo_stack_500mb.tif", overwrite = TRUE)
rm(stack)
```

In order to fit a (small) model, 500 raster cells are randomly sampled from the complete stack.
The binary response variable in `demo_stack` is located in the first column of `data` and needs to be of type `"factor"`.

```{r}
# Approach 1: no dedicated DataBackend, i.e. user needs to convert into a DT somehow
stack = terra::rast("demo_stack_500mb.tif")
data_train = as.data.table(spatSample(stack, 500))
data_train[, y := as.factor(y)]

# Approach 2: dedicated DataBackend for 'SpatRaster'
```

A mlr3 classification `task` is created and an SVM learner is fitted with the randomly sampled raster cells.

```{r}
task = as_task_classif(data_train, target = "y", positive = "1")

learner_svm = lrn("classif.svm")
learner_svm$train(task)
```

The `PredictionRaster` class controls the splitting of the raster stack into chunks.
The most important parameter is the `chunksize` which controls size of processed raster chunks.

The automatic detection of this parameter is error-prone since different {future} plans and {mlr3} learners will consume a highly varying amount of memory.

Note that the prediction is not executed at this point, the object is just constructed.

## Prediction

```{r}
data_predict = subset(stack, 1:4)

# Approach 1: S3 dispatch
learner_svm$predict_newdata(newdata = spatial_data_predict, task = task, chunksize = 200, filename = "pred.grd")

# Approach 2: Standalone function
predict_raster(task, learner, chunksize = 100L, filename = "target.tif")
```
