---
title: "Benchmarking parallel predictions"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Benchmarking parallel predictions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  options(width = 120),
  fig.path = "./"
)
```

This benchmark was run on a MacBook Pro 2020 with the following specs

- Intel i7-1068NG7 (8) @ 2.30GHz
- 32 GB DDR4 RAM

Note that the differences between the parallel and sequential timings will increase for larger objects as the overhead for starting the parallel workers and collecting the results will decrease.

It is not fully clear why the parallel approach of the {terra} package is slow than its sequential counterpart but it might relate to the single-core performance of the machine the benchmark was run on in combination with the overhead associated with starting the parallel cluster the way it is done in the {terra} package.

```{r prepare}
library(mlr3)
library(mlr3spatial)
library(future)
library(bench)
library(stars)
library(rpart)
```

## Small files

```{r prepare-small}
# SpatRaster demo stack
stack_classif = demo_stack_spatraster(50)
value = data.table::data.table(ID = c(0, 1), y = c("negative", "positive"))
terra::setCats(stack_classif, layer = "y", value = value)
colnames = names(stack_classif)
file = tempfile(fileext = ".tif")
terra::writeRaster(stack_classif, file)

# tasks
stack_classif = terra::rast(file)
backend = DataBackendSpatial$new(stack_classif)
task = as_task_classif(backend, target = "y", positive = "positive")

set.seed(42)
row_ids = sample(1:task$nrow, 50)

learner = lrn("classif.rpart")
learner$train(task, row_ids = row_ids)

# non-mlr3 model
rpart = rpart::rpart(y ~ ., task$data(rows = row_ids))
```

```{r benchmark-small}
bm = bench::mark(

  "01-mlr3-terra-4-cores" = {
    plan(multicore, workers = 4)
    predict_spatial(task, learner, chunksize = 2000L)
  },

  "02-terra-4-cores" = terra::predict(stack_classif, rpart, cores = 4, cpkgs = "rpart"),

  check = FALSE, filter_gc = FALSE, min_iterations = 3, memory = FALSE)

bm$`itr/sec` = NULL
bm$result = NULL
bm$`gc/sec` = NULL
bm$mem_alloc = NULL
bm$memory = NULL

print(bm)
```

```{r plot-benchmark-small}
library(ggplot2)
autoplot(bm, type = "ridge")
```

```{r save-plot, echo = FALSE, message = FALSE, fig.cap=""}
ggsave("plot-benchmark-small-1.png")
```

## Large files

```{r prepare-large}
# SpatRaster demo stack
stack_classif = demo_stack_spatraster(500)
value = data.table::data.table(ID = c(0, 1), y = c("negative", "positive"))
terra::setCats(stack_classif, layer = "y", value = value)
colnames = names(stack_classif)
file = tempfile(fileext = ".tif")
terra::writeRaster(stack_classif, file)

# tasks
stack_classif = terra::rast(file)
backend = DataBackendSpatial$new(stack_classif)
task = as_task_classif(backend, target = "y", positive = "positive")

set.seed(42)
row_ids = sample(1:task$nrow, 50)

learner = lrn("classif.rpart")
learner$train(task, row_ids = row_ids)

# non-mlr3 model
rpart = rpart::rpart(y ~ ., task$data(rows = row_ids))
```

```{r benchmark}
bm = bench::mark(

  "01-mlr3-terra-4-cores" = {
    plan(multicore, workers = 4)
    predict_spatial(task, learner, chunksize = 2000L)
  },

  "02-terra-4-cores" = terra::predict(stack_classif, rpart, cores = 4, cpkgs = "rpart"),

  check = FALSE, filter_gc = FALSE, min_iterations = 3, memory = FALSE)

bm$`itr/sec` = NULL
bm$result = NULL
bm$`gc/sec` = NULL
bm$mem_alloc = NULL
bm$memory = NULL

print(bm)
```

```{r plot-benchmark-large}
library(ggplot2)
autoplot(bm, type = "ridge", fig.cap="")
```

```{r save-plot-large, echo = FALSE, message = FALSE}
ggsave("plot-benchmark-large-1.png")
```
