---
title: "Benchmarking parallel predictions"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Benchmarking parallel predictions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  options(width = 120),
  fig.path = "./"
)
```

This benchmark was run on a MacBook Pro 2020 with the following specs

- Intel i7-1068NG7 (8) @ 2.30GHz
- 32 GB DDR4 RAM

Note that the differences between the parallel and sequential timings will increase for larger objects as the overhead for starting the parallel workers and collecting the results will decrease.

It is not fully clear why the parallel approach of the {terra} package is slow than its sequential counterpart but it might relate to the single-core performance of the machine the benchmark was run on in combination with the overhead associated with starting the parallel cluster the way it is done in the {terra} package.

```{r prepare}
library(mlr3)
library(mlr3learners)
library(mlr3spatial)
library(future)
library(bench)
library(stars)

# SpatRaster demo stack
stack = demo_stack_spatraster(size = 125, layers = 5)
backend = DataBackendSpatRaster$new(stack)
task = as_task_classif(backend, target = "y", positive = "TRUE")

# RasterBrick demo stack
stack_rasterbrick = demo_stack_rasterbrick(size = 125, layers = 5)
backend_raster = DataBackendRasterBrick$new(stack_rasterbrick, response = "y", response_is_factor = TRUE)
task_rasterbrick = as_task_classif(backend_raster, target = "y", positive = "1")

# Stars demo stack
stack_stars = stars::st_as_stars(stack_rasterbrick)
backend_stars = as_stars_backend(stack_stars, quiet = TRUE, response = "y.1", response_is_factor = TRUE)
task_stars =  as_task_classif(backend_stars, target = "y.1", positive = "1")

# SpatRaster learner
learner_svm = lrn("classif.svm")
learner_svm$parallel_predict = TRUE
set.seed(42)
row_ids = sample(1:task$nrow, 500)
learner_svm$train(task, row_ids = row_ids)

# RasterBrick learner
learner_svm_rasterbrick = lrn("classif.svm")
learner_svm_rasterbrick$parallel_predict = TRUE
set.seed(42)
row_ids = sample(1:task_rasterbrick$nrow, 500)
learner_svm_rasterbrick$train(task_rasterbrick, row_ids = row_ids)

# Stars learner
learner_svm_stars = lrn("classif.svm")
learner_svm_stars$parallel_predict = TRUE
set.seed(42)
row_ids = sample(1:task_stars$nrow, 500)
learner_svm_stars$train(task_stars, row_ids = row_ids)

# non-mlr3 model
e1071svm = e1071::svm(y ~ ., task$data(rows = row_ids))
```

```{r benchmark}
bm = bench::mark(
  "01-mlr3-terra-sequential" = {
    plan(multisession, workers = 1)
    predict_spatial_newdata(learner_svm, stack)
  },

  "02-mlr3-raster-sequential" = {
    plan(multisession, workers = 1)
    predict_spatial_newdata(learner_svm_rasterbrick, stack_rasterbrick)
  },

  "03-mlr3-stars-sequential" = {
    plan(multisession, workers = 1)
    predict_spatial_newdata(learner_svm_stars, stack_stars, quiet = TRUE)
  },

  "04-terra-sequential" = terra::predict(stack, e1071svm, cores = 1, cpkgs = "e1071"),

  "05-raster-sequential" = raster::predict(stack_rasterbrick, e1071svm),

  "06-stars-sequential" = {
    stack_stars_df = as.data.frame(split(stack_stars, "band"))
    predict(e1071svm, stack_stars_df)
  },

  "07-mlr3-terra-4-cores" = {
    plan(multisession, workers = 4)
    predict_spatial_newdata(learner_svm, stack)
  },

  "08-mlr3-raster-4-cores" = {
    plan(multisession, workers = 4)
    predict_spatial_newdata(learner_svm_rasterbrick, stack_rasterbrick)
  },

  "09-mlr3-stars-4-cores" = {
    plan(multisession, workers = 4)
    predict_spatial_newdata(learner_svm_stars, stack_stars, quiet = TRUE)
  },

  "10-terra-4-cores" = terra::predict(stack, e1071svm, cores = 4, cpkgs = "e1071"),

  "11-raster-4-cores" = {
    library(raster)
    library(e1071)
    beginCluster(4, type = "PSOCK")
    clusterR(stack_rasterbrick, predict, args = list(model = e1071svm))
  },

  check = FALSE, filter_gc = FALSE, min_iterations = 3, memory = FALSE)

bm$mem_alloc = NULL
bm$`itr/sec` = NULL
bm$result = NULL
bm$`gc/sec` = NULL
bm$memory = NULL

print(bm)
```

```{r plot-benchmark, fig.cap="Benchmark plot"}
library(ggplot2)
autoplot(bm, "ridge")
```

```{r save-plot, echo = FALSE, message = FALSE}
ggsave("plot-benchmark-1.png")
```
