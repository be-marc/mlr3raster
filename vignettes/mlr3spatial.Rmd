---
title: "Getting started"
output: 
  rmarkdown::html_vignette:
    df_print: paged
vignette: >
  %\VignetteIndexEntry{Getting started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = TRUE
)
```

## Introduction

{mlr3spatial} adds [mlr3::DataBackend]s for spatial classes ([terra::SpatRaster], [raster::brick], [sf::sf]).
In addition, direct predictions to objects of these classes are supported.
The direct return is a [mlr3::Prediction] object as for all other `predict()` returns in the {mlr3} ecosystem.
Besides, the respective spatial objects can be written to disk and loaded into the session for further analysis.

Essentially, {mlr3spatial} takes of the burden of converting spatial objects into a plain `data.table` and then coercing the predicted values back into the spatial object while making sure to not loose the spatial reference.

There is one more goodie in the bag.
Thanks to mlr3's ability to predict in parallel with any learner, {mlr3spatial} prediction can also make use of future-based parallelization and speed up the predictions of spatial objects.
Often enough, spatial predictions are quite large (in the millions of values) and efficient parallelization can save some time here.
See the vignette on ["Benchmarking parallel predictions"](https://mlr3spatial.mlr-org.com/articles/benchmark.html) for details.

In the following, we showcase a step-by-step example how to handle a multi-layer raster object from package {terra}.

## Use Case - {terra} objects

### Data Preparation

Spatial objects are not included as built-in datasets into the package due to their size. 
Some helper functions like `demo_stack_spatraster()` are available to create such.

The `SpatRaster` consists of 500 columns and rows and contains five layers with each layer representing a variable.

The `"Error in (function (x)  : attempt to apply non-function"` error can be ignored - this is an internal issue of the {terra} package during object creation and does not affect usage.

```{r}
library("mlr3")
library("mlr3spatial")
library("mlr3learners")
library("terra")
library("e1071")
```

First, a {mlr3} classification `task` is created and a SVM learner is fitted with randomly sampled raster cells.

```{r, error=TRUE}
tif = system.file("tif/L7_ETMs.tif", package = "stars")
stack = stars::read_stars(tif)

backend = as_data_backend(stack)
task = as_task_regr(backend, target = "layer.1")

print(task)
```

For large raster files with millions of values it helps to predict in parallel.
To enable this, set `learner$parallel_predict = TRUE` and initiate a parallel plan via {future}.
This required {mlr3} >= 0.12.0.

```{r}
learner_svm = lrn("regr.svm")
set.seed(42)
row_ids = sample(1:task$nrow, 500)
learner_svm$train(task, row_ids = row_ids)

print(learner_svm)
```

### Prediction

For prediction `predict_spatial()` is used.
It will return a raster file which contains the predictions.
Users can select which R spatial format the returned raster should have.

In the following, we will compare the way to conduct the prediction using {mlr3spatial} with the "native" way of fitting an `e1071::svm()` model and predicting with `terra::predict()`.

#### mlr3spatial

```{r}
ras = predict_spatial(task, learner_svm)

print(ras)
```

#### stars

Since the layers are merged in a {stars} object, one first need to split them up and convert them into a regular data.table.
Next, the column names need to be adjusted to match the ones of the training data.
Afterwards, the `data.frame` generic of `predict()` can be called.
Finally, the predictions need to be injected into a stars object again.

(All of these steps are happening internally in {mlr3spatial}).

```{r}
svm_e1071 = e1071::svm(layer.1 ~ ., data = task$data(rows = row_ids))
stars_stack = as.data.table(split(stack, "band"))
stars_stack[, c("x", "y", "X1")] = NULL
colnames(stars_stack) = task$feature_names

stars_pred = predict(svm_e1071, stars_stack)

# subset stars object to one band only
stars_pred_ras = stack[,,,1]
# rename the layer name
names(stars_pred_ras) = "pred"
# assign predictions
stars_pred_ras$pred = stars_pred

print(stars_pred_ras)
```

### Output consistency

Now that we have executed two predictions, we would like to verify that these are actually identical.

```{r}
all.equal(as.numeric(stars_pred_ras$pred), as.numeric(values(ras)))
```

We see some very minor differences which most likely relate to rounding.
